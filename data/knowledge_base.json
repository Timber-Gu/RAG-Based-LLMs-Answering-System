[
  {
    "id": "2506.18887v1_abstract",
    "title": "Steering Conceptual Bias via Transformer Latent-Subspace Activation",
    "content": "Title: Steering Conceptual Bias via Transformer Latent-Subspace Activation\n\nAbstract: This work examines whether activating latent subspaces in language models\n(LLMs) can steer scientific code generation toward a specific programming\nlanguage. Five causal LLMs were first evaluated on scientific coding prompts to\nquantify their baseline bias among four programming languages. A static\nneuron-attribution method, perturbing the highest activated MLP weight for a\nC++ or CPP token, proved brittle and exhibited limited generalization across\nprompt styles and model scales. To address these limitations, a\ngradient-refined adaptive activation steering framework (G-ACT) was developed:\nper-prompt activation differences are clustered into a small set of steering\ndirections, and lightweight per-layer probes are trained and refined online to\nselect the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably\nbiases generation towards the CPP language by increasing the average probe\nclassification accuracy by 15% and the early layers (0-6) improving the probe\nclassification accuracy by 61.5% compared to the standard ACT framework. For\nLLaMA-3.3 70B, where attention-head signals become more diffuse, targeted\ninjections at key layers still improve language selection. Although per-layer\nprobing introduces a modest inference overhead, it remains practical by\nsteering only a subset of layers and enables reproducible model behavior. These\nresults demonstrate a scalable, interpretable and efficient mechanism for\nconcept-level control for practical agentic systems.",
    "source": "http://arxiv.org/abs/2506.18887v1",
    "authors": [
      "Vansh Sharma",
      "Venkat Raman"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "I.2.7; I.2.6; I.2.1; D.3.3; C.4"
    ],
    "type": "abstract"
  },
  {
    "id": "2506.18887v1_content",
    "title": "Steering Conceptual Bias via Transformer Latent-Subspace Activation",
    "content": "arXiv:2506.18887v1 [cs.AI] 23 Jun 2025Steering Conceptual Bias via Transformer Latent-Subspace Activation Vansh Sharma∗ University of MichiganVenkat Raman University of Michigan Abstract This work examines whether activating latent subspaces in language models (LLMs) can steer scientific code generation toward a specific programming language. Five causal LLMs were first evaluated on scientific coding prompts to quantify their baseline bias among four programming languages. A static neuron-attribution method, perturbing the highest activated MLP weight for a ‘C++ or CPP’ token, proved brittle and exhibited limited generalization across prompt styles and model scales. To address these limitations, a gradient-refined adaptive activation steering framework (G-ACT) was developed: per-prompt activation differences are clus- tered into a small set of steering directions, and lightweight per-layer probes are trained and refined online to select the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably biases generation towards the CPP language by increas- ing the average probe classification accuracy by 15% and the early layers (0–6) improving the probe classification accuracy by 61.5 % compared to the standard ACT framework. For LLaMA-3.3 70B, where attention-head signals become more diffuse, targeted injections at key layers still improve language selection. Although per-layer probing introduces a modest inference overhead, it remains practical by steering only a subset of layers and enables reproducible model behav- ior. These results demonstrate a scalable, interpretable and efficient mechanism for concept-level control for practical agentic systems. Keywords: Activation Steering, Latent Space Activation, Activation Patching, Neuron Attribution, Privileged Basis, Code Generation, Reproducibility ∗Corresponding Author:  Preprint. Under review. 1 Introduction Large language models (LLMs) have rapidly evolved into sophisticated natural language processors, enabling the development of agentic systems that autonomously orchestrate complex workflows [Wang et al., 2024a, Sharma and Raman, 2024]. A particularly striking trend is the adoption of LLM -driven agents for automated code generation. By incorporating plugin architectures that expose external APIs, these agents extend beyond text synthesis: agents can invoke specialized tools [Wang et al., 2024b] and execute command-line operations [OpenAI, 2021, Lu et al., 2024]. This expanded action space has already powered a variety of real-world applications - from LLM-based robotic controllers [Wang et al., 2023, Kannan et al., 2024, Yang et al., 2024] to automated scientific experimentation [Gao et al., 2024, Gridach et al., 2025] platforms - highlighting the remarkable success of these agents. Despite the growing utility of LLM agents for high -level scripting and automation, their application to scientific code generation remains unexplored. Scientific software predominantly relies on C++ or CPP, CUDA and other low -level languages that are sparsely represented in most pretraining datasets. As a result, LLM -generated implementations often exhibit syntactic or semantic errors, leading to compilation failures or unstable behavior at runtime [Zhang et al., 2023]. In addition, current agents are heavily dependent on user-defined control primitives and meticulously engineered prompts, which can be misinterpreted and give rise to unpredictable execution paths [Kim et al., 2025, Krishnan, 2025, Gridach et al., 2025]. One possible solution is to augment function definitions and syntax using a retrieval augmented generation (RAG) framework; however, Xiao et al. [2023] and Yona et al. [2025] report unexplained vulnerability linked to \"attention sinks\" or first token bias, causing model behavior to diverge due to token repetition in long interactions, commonly seen in RAG. Another failure mode arises from the use of LMs that have been trained or fine -tuned on undisclosed corpora and then subjected to opaque alignment procedures, especially for MoE models [Nishu et al., 2025]. Such processes can inadvertently skew the model’s output toward a particular programming language or coding style, further eroding its ability to generate correct generalizable code across the various low-level languages prevalent in scientific computing during agentic applications with long repeated interactions. To investigate these bottlenecks, a curated benchmark of scientific coding challenges is introduced to reveal the implicit language preference of an LLM when presented with a given problem. Targeted probing techniques are then applied to identify subgraphs or subspaces in the model whose activation strongly correlates with that preference. In the privileged basis of the model [Zhang and Nanda, 2024], often termed native MLP activation axes, each coordinate encodes a distinct functional characteristic (here the coding language preference). This basis is a consequence of elementwise non-nonlinearities (e.g., ReLU, GELU) breaking rotational symmetry and the coordinate -wise biases introduced by optimizers such as Adam [Nelson Elhage and Olah, 2023]. Since these axes remain (approximately) disentangled, selectively amplifying or suppressing a single coordinate produces clear causal shifts in token probabilities [Elhage et al., 2022]. In this basis, an effective weight vector for any neuron can be derived and its direct influence on features can be decoded. The external perturbation of this neuron’s activation along the identified axis then reliably steers the model toward generating code in the desired programming language. Contribution of this work: 1.A curated suite of simple and complex scientific programming prompts designed to system- atically evaluate programming language selection behavior across targeted coding tasks. 2.A proof-of-concept method that locates the single MLP weight most correlated with the target concept (CPP language in this case) and perturbs it to bias model preference, demonstrating the feasibility and fragility of manual neuron edits for style control. 3.A scalable method that trains lightweight per-layer probes refined during inference via cross-entropy loss. This approach reliably steers LLMs toward the CPP language (or any target domain) with minimal runtime overhead and embeds reproducible transformation matrices for consistent behavior across multiple model deployments. 2 2 Related Work Reverse engineering neural networks to drive/steer a specific behavior, known as mechanistic in- terpretability, is an emerging field [Wang et al., 2022, Templeton et al., 2024, Olsson et al., 2022]. Its primary objective is to identify causal relationships within model activations Jiang et al. [2024], Chen et al. [2024], Rodrigues et al. [2024] thereby revealing complex functional roles [Condori and Bruno, 2021, Szandała, 2023] and enabling the targeted modulation [Huang et al., 2025] or ablation of individual neurons. Supervised fine-tuning, weight modulation techniques, and RLHF represent direct intervention strategies for model steering [Dathathri et al., 2019, Meng et al., 2022]. Although effective, these methods impose substantial computational overhead and can inadvertently compromise the robustness and general performance of the model [Brown et al., 2023]. The method using corrupted inputs as a baseline distribution to resample neuron activation, known as Activation Patching, has been widely used to achieve fine-grained control over the model output [Kramár et al., 2024, Geiger et al., 2022, Meng et al., 2022]. A typical causal attribution method quantifies the negative impact on model output by deleting specific neuron activations, a more trivial approach compared to Activation Patching. In such methods, extensive model sweeps are conducted to evaluate the results of neuron modification, leading to millions of model evaluations [Kramár et al., 2024]. Studies such as [Park et al., 2025, Yeo et al., 2025], have focused on suppressing hallucinations in LLMs within different modalities using activation patching. Recent studies using similar forms of neuron attribution have typically been applied to multiple choice question benchmarks [Wang et al., 2025, Davies, 2025], rather than real-world deployment scenarios. In contrast to previous work, this study presents a different approach for the inference-time adaptive steering algorithm [Wang et al., 2025] by incorporating gradient-based refinement, offering a more efficient and precise mechanism for steering large-scale models. 3 Methodology Autoregressive decoder-only transformers convert embedded tokens into high -dimensional latent representations that are successively refined by the attention mechanism [Vaswani et al., 2017] and deep MLP blocks for output generation. Residual connections carry a persistent residual stream: combining each MLP input with its output to preserve and enhance contextual features before the LM head decodes the final latent stream into tokens. In particular, individual neurons operate directly on the residual stream, a central information pathway through transformer layers. Neurons specialized in the detection of specific features within this stream exhibit a strong alignment between their weight vectors and the corresponding features, characterized by high cosine similarity [Meng et al., 2022]. This property forms the basis for the methods explained in the following sections. 3.1 Neuron Attribution: Static Method Building upon the previously mentioned alignment property between weights and features, the static method involves directly decoding the neuron weight vectors through the LM-head, thus converting the neuron weights into interpretable token-level probability distributions. This approach aligns conceptually with the “Golden Gate\" investigation by Templeton et al. [2024] and work by Davies [2025]. A transformer with Llayers processes an input token sequence x1, . . . , x n∈V(vocabular",
    "source": "http://arxiv.org/abs/2506.18887v1",
    "authors": [
      "Vansh Sharma",
      "Venkat Raman"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "I.2.7; I.2.6; I.2.1; D.3.3; C.4"
    ],
    "type": "content"
  },
  {
    "id": "2506.18812v1_abstract",
    "title": "Learning Physical Systems: Symplectification via Gauge Fixing in Dirac Structures",
    "content": "Title: Learning Physical Systems: Symplectification via Gauge Fixing in Dirac Structures\n\nAbstract: Physics-informed deep learning has achieved remarkable progress by embedding\ngeometric priors, such as Hamiltonian symmetries and variational principles,\ninto neural networks, enabling structure-preserving models that extrapolate\nwith high accuracy. However, in systems with dissipation and holonomic\nconstraints, ubiquitous in legged locomotion and multibody robotics, the\ncanonical symplectic form becomes degenerate, undermining the very invariants\nthat guarantee stability and long-term prediction. In this work, we tackle this\nfoundational limitation by introducing Presymplectification Networks (PSNs),\nthe first framework to learn the symplectification lift via Dirac structures,\nrestoring a non-degenerate symplectic geometry by embedding constrained systems\ninto a higher-dimensional manifold. Our architecture combines a recurrent\nencoder with a flow-matching objective to learn the augmented phase-space\ndynamics end-to-end. We then attach a lightweight Symplectic Network (SympNet)\nto forecast constrained trajectories while preserving energy, momentum, and\nconstraint satisfaction. We demonstrate our method on the dynamics of the\nANYmal quadruped robot, a challenging contact-rich, multibody system. To the\nbest of our knowledge, this is the first framework that effectively bridges the\ngap between constrained, dissipative mechanical systems and symplectic\nlearning, unlocking a whole new class of geometric machine learning models,\ngrounded in first principles yet adaptable from data.",
    "source": "http://arxiv.org/abs/2506.18812v1",
    "authors": [
      "Aristotelis Papatheodorou",
      "Pranav Vaidhyanathan",
      "Natalia Ares",
      "Ioannis Havoutis"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "type": "abstract"
  },
  {
    "id": "2506.18812v1_content",
    "title": "Learning Physical Systems: Symplectification via Gauge Fixing in Dirac Structures",
    "content": "arXiv:2506.18812v1 [cs.RO] 23 Jun 2025Learning Physical Systems: Symplectification via Gauge Fixing in Dirac Structures Aristotelis Papatheodorou*, Pranav Vaidhyanathan*, Natalia Ares, Ioannis Havoutis Department of Engineering Science, University of Oxford, Oxford, OX1 3PJ, United Kingdom Abstract —Physics-informed deep learning has achieved re- markable progress by embedding geometric priors, such as Hamiltonian symmetries and variational principles, into neural networks, enabling structure-preserving models that extrapolate with high accuracy. However, in systems with dissipation and holonomic constraints, ubiquitous in legged locomotion and multibody robotics, the canonical symplectic form becomes de- generate, undermining the very invariants that guarantee stabil- ity and long-term prediction. In this work, we tackle this foun- dational limitation by introducing Presymplectification Networks (PSNs), the first framework to learn the symplectification lift via Dirac structures, restoring a non-degenerate symplectic geometry by embedding constrained systems into a higher-dimensional manifold. Our architecture combines a recurrent encoder with a flow-matching objective to learn the augmented phase-space dynamics end-to-end. We then attach a lightweight Symplectic Network (SympNet) to forecast constrained trajectories while preserving energy, momentum, and constraint satisfaction. We demonstrate our method on the dynamics of the ANYmal quadruped robot, a challenging contact-rich, multibody system. To the best of our knowledge, this is the first framework that effectively bridges the gap between constrained, dissipative mechanical systems and symplectic learning, unlocking a whole new class of geometric machine learning models, grounded in first principles yet adaptable from data. I. I NTRODUCTION Physics-Informed deep learning has seen remarkable suc- cess in recent years, with Physics Informed Neural Networks (PINNs) [1] excelling in different scientific fields [2, 3, 4, 5]. This advancement is due to the development of neural ar- chitectures that incorporate geometric structures inherent in physical systems, such as Hamiltonian, Lagrangian, or port- Hamiltonian forms. These structures enable these architectures to conserve energy and momentum, extend their predictive ca- pabilities far beyond the training data, and learn from relatively limited datasets [6]. Notable examples include Hamiltonian Neural Networks (HNNs) [7], Lagrangian Neural Networks (LNNs) [8] as well as Symplectic Networks (SympNets) [9], together with more recent Symplectic Neural Flows [10] and port-Hamiltonian ODE nets [11]. At the heart of these approaches and virtually in almost all aspects of physics, lies the canonical symplectic two form, ω=dqi∧dpi, *These authors contributed equally to this work. Correspondence to: {aristotelis, pranav  Paper presented at ”Equivariant Systems: Theory and Applications in State Estimation, Artificial Intelligence and Control”, Robotics: Science and Systems (RSS) 2025 Workshop.defined on the cotangent bundle T∗Qof a configuration manifold Q. Since ωis both closed (dω= 0 ) and non- degenerate (its bilinear pairing has no null directions), this supplies the geometric machinery that turns a Hamiltonian H(q,p)into a vector field via XH⌟Ω = dH [12]. This construction guarantees phase-space volume preservation (Li- ouville’s theorem) and locks in first integrals such as total energy and linear/angular momentum that are vital for long- horizon prediction with sparse data. However, many real-world mechanisms violate this as- sumption. Systems with rigid holonomic constraints and foot–ground contacts degenerate the symplectic form, splitting phase space into uncontrolled directions where invariants are no longer protected. In practice, physics informed models confronted with contacts or closed kinematic chains suffer energy blow-up, constraint drift, and brittle generalization. Soft-penalty methods can reduce, but never eliminate, these pathologies so far [13]. However, in their seminal work on symplectic optimization, Franc ¸a et al. [14], introduced the concept of symplectification in the context of integrators. Symplectification refers to the process of recovering a non- degenerate symplectic form from a degenerate one, by em- bedding the original phase space into a higher-dimensional manifold. Concretely, given a presymplectic manifold (S, ω) whose 2-form ωhas rank deficiencies induced by holonomic constraints, we can attach: •a clock coordinate q0=twith conjugate momentum p0, and •the Lagrange multipliers λatogether with their conjugate momenta πa. The resulting extended bundle: T∗eQ:=T∗Q×T∗\u0000 R×Rm\u0001 , (Q,P) := ( q0, qi, λa;p0, pi, πa),(1) carries the canonical symplectic form: eΩ =dq0∧dp0+dqi∧dpi+dλa∧dπa, (2) which is closed and non-degenerate by construction. Choos- ing the extended Hamiltonian eH(Q,P) =H(q,p) +p0+ λaϕa(q), wheredπa dt=−ϕa(q) = 0 encodes the original constraints, Hamilton’s equations on (T∗eQ,eΩ)reproduce the constrained dynamics once the Dirac gauge : q0=t, p0+H+λaϕa= 0, πa= 0, (3) Dirac Lift Integration t+1t(a) (t-T):t qt-T:t 𝜙(q ) t-T:t (p p ) 0,(t-T:t-1), ctrl,t pt-T:t λt-T:tt qt 𝜙(q)t p0,t pt λt GRU Flow Matchingt+1 qt+1 𝜙(q )t+1 p0,t+1 pt+1 λt+1 Lifted SympNet inpainting (b) Fig. 1: (a) Our framework lifts the original phase-space to a fully conservative higher-dimensional manifold using the Dirac- lifted symplectification procedure. Then the dynamics are integrated along the surface of the lifted manifold. (b) The Dirac-lifted symplectification procedure is implemented as a flow-matching, inpainting objective using a GRU. The procedure maps the control-induced conjugate momenta ( pctrl,t ) to the total conjugate momenta that include the system’s dissipation ( p0,t). An additional context ( T) of 10 timesteps is supplied to the network. Then, the lifted phase-space is supplied to a SympNet that performs the next timestep prediction. is imposed. In effect, symplectification trades degeneracy for auxiliary coordinates, thereby restoring the geometric back- bone needed for structure-preserving neural networks [15, 16]. A. Dirac Structures: The unifying language While the construction above is often introduced ad hoc, it can be stated elegantly in the language of Dirac structures . A Dirac structure on a vector space Vis a maximal isotropic subspace D⊂V⊕V∗with respect to the symmetric pairing ⟨(u, α),(v, β)⟩=α(v) +β(u)[17]. The graphs of closed 2-forms ( graph ω♭) recover presymplectic geometry, whereas the graphs of bivectors ( graph π♯) recover Poisson geometry; Dirac structures therefore unify presymplectic and Poisson mechanics within a single framework [18]. For constrained mechanical systems, the bundle: D(q) =\b (v, α)∈TqQ⊕T∗ qQ| α(v′) =ω(v, v′)for all v′∈TqQ , captures simultaneously the admissible motions vand the consistent constraint forces α. Symplectification corresponds to lifting Dto the canonical graph, grapheΩ♭, on the extended space, after which every classical symplectic tool, including variational integrators and backward-error analysis, becomes available. B. Our Contributions Building on this geometric foundation, we make the follow- ing contributions: 1)Presymplectification Network (PSN). We propose the first neural architecture that learns the full presymplec- tification lift Ψθ: (q,p)7→(Q,P), where the network outputs the Lagrange multipliers, their conjugate mo- menta, and the clock coordinate.2)Flow matching training. The core module of the PSN consists of a model that combines a Gated-Recurrent Unit (GRU) network with a normalizing-flow-style ve- locity head, wrapped inside a differentiable implicit midpoint integration layer. This yields a map compatible with the learned Dirac lift [19, 20]. 3)Dynamics prediction module. As a downstream task, we use SympNets to predict the dynamics of a complex physical system. In order to demonstrate, the effectiveness of this pipeline we choose to predict the locomotion dynamics of the ANYmal quadruped robot [21], a non-holonomic, multibody system with contact constraints that is often considered to be amongst the most challenging problems in robotics. II. M ETHODS This section formalizes the learning task illustrated in Fig. 1, details the Presymplectification Network (PSN) architecture, introduces our flow-matching training objective, and describes the downstream SympNet step predictor that together form the complete pipeline. Throughout, we write x= (q,p)∈T∗Q for the physical state and z= (Q,P)∈T∗eQfor its lifted counterpart. A. Problem Statement The ANYmal [21] is a torque-controlled quadrupedal robot engineered for agile locomotion and resilient interaction with unstructured environments. Unlike many legged platforms, it features relatively heavy limbs, making their inertial and Coriolis effects dynamically significant and thus, posing a substantial challenge for accurate modeling and control. How- ever, our modular pipeline alleviates these difficulties by re- parametrizing the quadruped’s dynamics in the lifted Hamilto- nian phase-space ( T∗eQ) and predict its dynamics on this lifted 0 5 10 15 20 25 30 Time [s]1.0 0.5 0.00.51.01.52.0Conjugate Momentum p0Actual Prediction p00.00.20.40.60.81.0Absolute Error (±) Fig. 2: (Left) Predicted conjugate momentum (green) against the actual conjugate momentum (yellow). (Right) Absolute error for the conjugate momentum. manifold. More specifically, the dynamics of the quadruped can be expressed by: M(q)¨q+C(q,˙q) =Bu+Jc(q)⊤Fc, s.t.:ϕi(q) = 0 ,∀i∈ Ic,(4) where M(q)represents the mass matrix, C(q,˙q)the nonlinear dynamics terms, Bthe control-input ( u)selection matrix, Jc(q)the concatenated contact Jacobians and Fcthe contact wrenches. The scleronomic contact constraint ϕi(q) = 0 is active only for the feet ( i) that are in contact, within the contact setIc. The configuration space (Q)comprises a composite lie group SE(3)×R12, while its tangent space TQ lives in the euclidean R18spa",
    "source": "http://arxiv.org/abs/2506.18812v1",
    "authors": [
      "Aristotelis Papatheodorou",
      "Pranav Vaidhyanathan",
      "Natalia Ares",
      "Ioannis Havoutis"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "type": "content"
  },
  {
    "id": "2506.18797v1_abstract",
    "title": "A Multi-view Divergence-Convergence Feature Augmentation Framework for Drug-related Microbes Prediction",
    "content": "Title: A Multi-view Divergence-Convergence Feature Augmentation Framework for Drug-related Microbes Prediction\n\nAbstract: In the study of drug function and precision medicine, identifying new\ndrug-microbe associations is crucial. However, current methods isolate\nassociation and similarity analysis of drug and microbe, lacking effective\ninter-view optimization and coordinated multi-view feature fusion. In our\nstudy, a multi-view Divergence-Convergence Feature Augmentation framework for\nDrug-related Microbes Prediction (DCFA_DMP) is proposed, to better learn and\nintegrate association information and similarity information. In the divergence\nphase, DCFA_DMP strengthens the complementarity and diversity between\nheterogeneous information and similarity information by performing Adversarial\nLearning method between the association network view and different similarity\nviews, optimizing the feature space. In the convergence phase, a novel\nBidirectional Synergistic Attention Mechanism is proposed to deeply synergize\nthe complementary features between different views, achieving a deep fusion of\nthe feature space. Moreover, Transformer graph learning is alternately applied\non the drug-microbe heterogeneous graph, enabling each drug or microbe node to\nfocus on the most relevant nodes. Numerous experiments demonstrate DCFA_DMP's\nsignificant performance in predicting drug-microbe associations. It also proves\neffectiveness in predicting associations for new drugs and microbes in cold\nstart experiments, further confirming its stability and reliability in\npredicting potential drug-microbe associations.",
    "source": "http://arxiv.org/abs/2506.18797v1",
    "authors": [
      "Xin An",
      "Ruijie Li",
      "Qiao Ning",
      "Shikai Guo",
      "Hui Li",
      "Qian Ma"
    ],
    "categories": [
      "cs.LG"
    ],
    "type": "abstract"
  },
  {
    "id": "2506.18797v1_content",
    "title": "A Multi-view Divergence-Convergence Feature Augmentation Framework for Drug-related Microbes Prediction",
    "content": "arXiv:2506.18797v1 [cs.LG] 23 Jun 2025JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2024 1 A Multi-view Divergence-Convergence Feature Augmentation Framework for Drug-related Microbes Prediction Xin An1,6†, Ruijie Li1,3,6†Student Member, IEEE , Qiao Ning1,2,5∗, Shikai Guo1,3,6, Hui Li1, Qian Ma1 Abstract —In the study of drug function and precision medicine, identifying new drug-microbe associations is crucial. However, current methods isolate association and similarity anal- ysis of drug and microbe, lacking effective inter-view optimization and coordinated multi-view feature fusion. In our study, a multi- view Divergence-Convergence Feature Augmentation framework for Drug-related Microbes Prediction (DCFA DMP) is proposed, to better learn and integrate association information and similar- ity information. In the divergence phase, DCFA DMP strengthens the complementarity and diversity between heterogeneous infor- mation and similarity information by performing Adversarial Learning method between the association network view and different similarity views, optimizing the feature space. In the convergence phase, a novel Bidirectional Synergistic Attention Mechanism is proposed to deeply synergize the complementary features between different views, achieving a deep fusion of the feature space. Moreover, Transformer graph learning is alternately applied on the drug-microbe heterogeneous graph , enabling each drug or microbe node to focus on the most rel- evant nodes. Numerous experiments demonstrate DCFA DMP’s significant performance in predicting drug-microbe associations. It also proves effectiveness in predicting associations for new drugs and microbes in cold start experiments, further confirming its stability and reliability in predicting potential drug-microbe associations. Index Terms —Drug-related Microbes Prediction, Divergence- Convergence, Adversarial Learning, Bidirectional Synergistic Attention Mechanism I. I NTRODUCTION AT birth, humans consist exclusively of their own eu- karyotic cells. However, during the early years of life, skin, mouth, and gut are colonized by a diverse array of bacteria, archaea, fungi, and viruses. This community of cells is referred to as the human microbiome [1]. Dysbiosis within the microbiome has been linked to various diseases, including 1 Department of Information Science and Technology, Dalian Maritime University, Dalian, 116026, P.R. China. 2 School of Artificial Intelligence and Computer Science, Jiangnan Univer- sity, Wuxi, 214122, P.R. China. 3 DUT Artificial Intelligence Institute, Dalian, P.R. China. 4 School of Computer Science and Engineering, Northeastern University, Shenyang, 110819, P.R. China. 5 Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, P.R. China 6 Dalian Key Laboratory of Artificial Intelligence, Dalian, P.R. China. * To whom correspondence should be addressed at  † Xin An and Ruijie Li contributed equally to this work and should be considered co-first authors.inflammatory bowel disease, multiple sclerosis, diabetes (type 1 and type 2), allergies, asthma, autism, and cancer [2]. Early in drug discovery, it was recognized that the microbiota plays a crucial role in the efficacy of therapeutic compounds. However, with the ongoing emergence of antimicrobial resistance, there is an urgent need to systematically determine the interactions between microbes and drugs to facilitate drug development. Therefore, discovering novel microbiome-drug associations is of great significance in drug efficacy studies and precision medicine. An increasing body of literature has reported the links between microbes and drugs. For example, Zimmermann et al. [3] found that the activity and toxicity of many oral drugs can be altered by bacterial enzymes produced by the human gut microbiota, potentially influencing treatment outcomes. Among these, the gut bacterium Bacteroides thetaiotaomicron is a prolific drug metabolizer capable of metabolizing a wide range of drugs, including diltiazem. Furthermore, Blaser et al. [4] suggested that the skin microbiome plays a crucial role in antibiotic resistance in Staphylococcus aureus infections. These findings underscore the importance of systematically elucidating microbe–drug interactions to advance drug devel- opment and address the challenges posed by antimicrobial resistance. In recent years, graph learning has become increasingly prevalent in predicting microbiome-drug associations due to its remarkable capacity to model graph-structured data. Several variants, including Graph Convolutional Networks (GCN [5])-based approaches [6, 7, 8], Graph Attention Net- works (GAT [9])-based methods [10, 11], and Heterogeneous Graph Attention Networks (HAN [12])-based models [13] showing considerable promise in this task. For instance, NGMDA [14] builds a drug-microbe hetero- geneous graph that encodes the positional and topological features of drug and microbe nodes, combining different feature types from neighboring nodes and the entire hetero- geneous graph. DHDMP [15] constructs a hypergraph with dynamic topology, utilizing GCN to transfer node features to the heterogeneous graph, thereby enhancing neighbor feature representation learning. MKGCN [16] extracts features from microbes and drugs through multiple GCN layers, using kernel matrices to predict their associations. GACNNMDA [17] inte- grating GAT and CNN to predict microbiome-drug interactions using heterogeneous networks. Although these methods have shown promising results, they still have limitations. NGMDA 0000–0000/00$00.00 © 2024 IEEE JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2024 2 overlooks the complex relationships among multiple drugs and microbes. DHDMP cannot fully capture certain intricate long-distance correlations. MKGCN fails to capture complex structural and semantic relationships in heterogeneous net- works. Overall, although these graph learning-based models have shown promising results in drug-microbe prediction tasks, they still cannot fully leverage the information within heterogeneous networks and similarity networks. With the development of deep learning, an increasing number of researchers have proposed a series of computa- tional methods based on deep learning to detect potential microbiome-drug interactions [18, 19], achieving promising results. For instance, Zhu et al. [20] introduced a method called HMDAKATZ, which employs the KATZ metric to infer potential microbiome-drug associations. Long et al. [21] proposed the HNERMDA framework, which integrates meta- path2vec with bipartite network recommendations to predict potential microbiome-drug interactions. Additionally, Zhu et al. [22] designed a computational model called LRLSMDA, which uses the Laplacian regularized least squares algorithm to identify microbiome-drug associations. Tan et al. [23] proposed the GSAMDA model, which employs GAT-based and sparse autoencoder modules to learn both topological and attribute representations of nodes in heterogeneous networks. However, existing computational approaches typically suffer from isolated processing of association networks and similarity graphs, lacking optimization mechanisms to enhance informa- tional diversity. Furthermore, their feature fusion mechanisms fail to establish bidirectional synergistic relationships between divergent feature representations, ultimately resulting in sub- optimal integration of multi-source information. To address these challenges, we propose a multi-view divergence-convergence feature augmentation framework for drug-related microbes prediction, whose framework is shown in Figure 1. The contributions of this method are as follows: •We propose a transformer-based graph learning approach, where Transformer extends the receptive field of the GNN, facilitating a more comprehensive exploration of drug-microbe associations and GNNs capture essential structural information, guiding the Transformer to focus on key local features. •We introduce a novel divergence-convergence feature enhancement framework. In the divergence phase, an Adversarial Learning approach is employed to enhance the complementarity and diversity of information be- tween the association and similarity views. In the con- vergence phase, we propose a novel Bidirectional Syner- gistic Attention Mechanism (BSAM) to facilitate multi- dimensional interaction and fusion of the enhanced multi- view features. •Extensive experiments, including cold start and case stud- ies, show that the proposed method outperforms baseline models on benchmark datasets and proves the practicality of our model in drug localization tasks.II. R ELATED MATERIALS III. M ETHODOLOGY The framework consists of three main components: 1) Multi-view graph representation learning; 2) Divergence- Convergence feature enhancement strategy; 3) Drug-microbe association prediction. In the subsequent sections, we will provide a comprehensive review of each stage and present the essential details pertaining to our model. A. Multi-view graph representation learning 1) Feature convolution module: Different similarity rela- tionships can reflect the diverse semantic connections between drug and microbe nodes. Therefore, we constructed a K- nearest neighbor graph (KNN) based on the similarity matrix to capture the underlying structure of drugs and microbes in the feature space, and to learn embeddings that capture specific information. We denote Xdas the drug similarity matrix, and construct the binary adjacency matrix Adof the drug KNN graph based on the similarity between each pair of drugs. The specific definition of each entry Ad ijin the matrix Adis as follows: Ad ij=( 1,ifdj∈˜Nk(di) 0,otherwise(1) where ˜Nk(di) ={di} ∪Nk(di)represents the extended k- neighborhood set of drug di, where Nk(di)denotes the k- nearest neighbors of drug di. Similarly, we denote Xmas the microbe similarity matrix, and the speci",
    "source": "http://arxiv.org/abs/2506.18797v1",
    "authors": [
      "Xin An",
      "Ruijie Li",
      "Qiao Ning",
      "Shikai Guo",
      "Hui Li",
      "Qian Ma"
    ],
    "categories": [
      "cs.LG"
    ],
    "type": "content"
  },
  {
    "id": "2506.18791v1_abstract",
    "title": "Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers",
    "content": "Title: Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers\n\nAbstract: The evolution of Vision Transformers has led to their widespread adaptation\nto different domains. Despite large-scale success, there remain significant\nchallenges including their reliance on extensive computational and memory\nresources for pre-training on huge datasets as well as difficulties in\ntask-specific transfer learning. These limitations coupled with energy\ninefficiencies mainly arise due to the computation-intensive self-attention\nmechanism. To address these issues, we propose a novel Super-Pixel Based Patch\nPooling (SPPP) technique that generates context-aware, semantically rich, patch\nembeddings to effectively reduce the architectural complexity and improve\nefficiency. Additionally, we introduce the Light Latent Attention (LLA) module\nin our pipeline by integrating latent tokens into the attention mechanism\nallowing cross-attention operations to significantly reduce the time and space\ncomplexity of the attention module. By leveraging the data-intuitive patch\nembeddings coupled with dynamic positional encodings, our approach adaptively\nmodulates the cross-attention process to focus on informative regions while\nmaintaining the global semantic structure. This targeted attention improves\ntraining efficiency and accelerates convergence. Notably, the SPPP module is\nlightweight and can be easily integrated into existing transformer\narchitectures. Extensive experiments demonstrate that our proposed architecture\nprovides significant improvements in terms of computational efficiency while\nachieving comparable results with the state-of-the-art approaches, highlighting\nits potential for energy-efficient transformers suitable for edge deployment.\n(The code is available on our GitHub repository:\nhttps://github.com/zser092/Focused-Attention-ViT).",
    "source": "http://arxiv.org/abs/2506.18791v1",
    "authors": [
      "Suyash Gaurav",
      "Muhammad Farhan Humayun",
      "Jukka Heikkonen",
      "Jatin Chaudhary"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "type": "abstract"
  },
  {
    "id": "2506.18791v1_content",
    "title": "Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers",
    "content": "arXiv:2506.18791v1 [cs.CV] 23 Jun 2025Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers Suyash Gaurav∗ Tokyo International University Tokyo, JapanMuhammad Farhan Humayun∗ University of Turku Turku, FinlandJukka Heikkonen University of Turku Turku, Finland Jatin Chaudhary University of Turku Turku, Finland  Abstract The evolution of Vision Transformers has led to their widespread adaptation to different domains. Despite large-scale success, there remain significant challenges including their reliance on extensive computational and memory resources for pre-training on huge datasets as well as difficulties in task-specific transfer learn- ing. These limitations coupled with energy inefficiencies mainly arise due to the computation-intensive self-attention mechanism. To address these issues, we propose a novel Super-Pixel Based Patch Pooling (SPPP) technique that gener- ates context-aware, semantically rich, patch embeddings to effectively reduce the architectural complexity and improve efficiency. Additionally, we introduce the Light Latent Attention (LLA) module in our pipeline by integrating latent tokens into the attention mechanism allowing cross-attention operations to significantly reduce the time and space complexity of the attention module. By leveraging the data-intuitive patch embeddings coupled with dynamic positional encodings, our approach adaptively modulates the cross-attention process to focus on infor- mative regions while maintaining the global semantic structure. This targeted attention improves training efficiency and accelerates convergence. Notably, the SPPP module is lightweight and can be easily integrated into existing transformer architectures. Extensive experiments demonstrate that our proposed architecture provides significant improvements in terms of computational efficiency while achieving comparable results with the state-of-the-art approaches, highlighting its potential for energy-efficient transformers suitable for edge deployment. (The code is available on our GitHub repository:  Attention-ViT). 1 Introduction The self-attention mechanism which forms the core of the transformer architecture was originally designed to handle a variety of Natural Language Processing (NLP) tasks such as machine transla- tion Vaswani et al. [2017], sentiment classification Lin et al. [2017], Ambartsoumian and Popowich [2018] sentence prediction Devlin et al. [2018] reading comprehension Yang et al. [2019] etc. The mechanism has been further adapted to advanced reasoning models such as Generative Pretrained Transformer (GPT) Radford and Narasimhan [2018] and DeepSeek et. al. [2025]. The principal ∗These authors contributed equally and share first authorship. Preprint. Under review. advantage of the self-attention mechanism is its ability to effectively capture the long-range de- pendencies more efficiently as compared to its old rival i.e. the recurrent neural networks (RNNs). Concretely, self-attention enables the model to weigh the relevance of different tokens in a sequence relative to each other, regardless of their position. The adaptation of this approach towards Computer Vision tasks, first proposed by Dosovitskiy et.al, Dosovitskiy et al. [2021] allows the processing of 2D input image patches in a similar fashion compared to the word tokens in NLP tasks. Figure1illustrates this process in Vision Transformers (ViT) from the input image to the patch embeddings which are directly passed on to the multi-head self-attention modules. To exemplify, we use a resampled goldfish image from the ImageNet dataset to show the intermediate outputs generated during the embedding process. Considering the input image is: X∈RH×W×C. Figure 1: Illustration of the Patch Embedding Module for Vision Transformers In the provided example, the input image is resampled to 224 x 224 pixels and contains 3 color channels. It is then divided into 196 equal sized, non-overlapping patches of 16 x 16 using the following equation: N=H×W P2(1) Here, Ndenotes the number of patches (excluding the class token), HandWcorrespond to the height and width of the input image, respectively, and Pis the side length of each square patch (i.e., assuming square patches of size P×P). Each patch is flattened to form a vector, xi∈RP2·C,fori= 1, . . . , N . In the provided example, we have 196 different vectors of size 16×16×3 = 768 . Each flattened patch vector xiis projected to a lower-dimensional embedding space using a learnable linear transformation: E∈R(P2·C)×D, where Dis the transformer embedding dimension: zi=xiE∈RD(2) A key observation here is that the number of final patch embeddings scales linearly with the number of input image patches which in turn depends on the input image resolution and the individual patch size. In the subsequent multi-headed self-attention, each patch embedding is correlated against one another resulting in quadratic complexity i.e., O(N2). Considering the example as illustrated in Figure 1, there are 196patch embeddings which amount to (196)2≈38kpairwise correlation computations within the self-attention module. We introduce robust techniques to effectively reduce the embedding dimensions by intelligently fusing the input patches based on the inherent semantic structure. This in turn reduces the computational overhead of the self-attention module, while preserving and propagating rich semantic information to the deeper layers of the network to facilitate convergence and more efficient training. The main contributions of our work are as follows: 2 •We propose the novel Super-Pixel Based Patch Pooling (SPPP) algorithm to intelligently reduce the number of patch embeddings which are fed into the attention mechanism by merging the input image patches based on their intrinsic semantic properties. •We propose replacing the multi-headed attention modules with the novel Light Latent Attention (LLA) mechanism in the ViT architecture, enabling efficient cross-attention operations with latent tokens. •Our architectural modifications significantly reduce the time and space complexity of the attention mechanism which is the major bottleneck in the ViT architecture in terms of computational and temporal requirements. •We conduct extensive experiments and ablation studies on various public benchmark datasets to validate the effectiveness of our proposed techniques. 2 Background and Related Work Vision Transformers (ViTs) have shown remarkable success across various tasks from image clas- sification Dosovitskiy et al. [2021], Touvron et al. [2021], Liu et al. [2021], Wang et al. [2025] to more complex tasks including segmentation, Zheng et al. [2021], Xie et al. [2021], YUAN et al. [2021], Thisanke et al. [2023] object detection, Carion et al. [2020], Liu et al. [2022a], Zhao et al. [2024], Zhang et al. [2025] and video understanding Arnab et al. [2021], Bertasius et al. [2021], Chen et al. [2024]. Similarly, a large number of domain-specific studies utilizing transformer architectures also exist, such as medical image analysis Hatamizadeh et al. [2022], He et al. [2023], Aburass et al. [2025], remote sensing Hong et al. [2022], Yao et al. [2023], pose estimation Li et al. [2023] and action recognition Ahn et al. [2023] etc. Since the groundbreaking approach of replacing the tradi- tional convolutional operations entirely with attention-based architectures proposed by Dosovitskiy et.al Dosovitskiy et al. [2021], the ViT architecture has been studied vastly proposing improved, more robust variants of the originally proposed model. For instance, to mitigate the heavy computational burden, several works have proposed architectural modifications aimed at improving efficiency. DeiT Touvron et al. [2021] introduced knowledge distillation to train ViTs on smaller datasets without sacrificing accuracy. T2T-ViT Yuan et al. [2021] employed a tokens-to-token transformation that progressively aggregates information before applying self-attention. Similarly, MobileViT Mehta and Rastegari [2022] integrated convolutions into the transformer pipeline to enhance locality and reduce computational cost, making ViTs more viable for mobile settings. Other works like PoolFormer Yu et al. [2022] and PiT Heo et al. [2021] introduced hierarchical token reduction strategies and spatial pooling mechanisms to reduce input sequence length progressively. LeViT Graham et al. [2021] leveraged downsampling and hybrid convolutions to strike a better latency-accuracy trade-off. These variants highlight a trend toward building lightweight and scalable ViTs, but they often compromise the richness of patch representations or spatial context. The self-attention mechanism scales quadratically with input sequence length. To address this, Linformer Wang et al. [2020] approximated self-attention with low-rank projections, while Nys- trömformer Xiong et al. [2021] introduced kernel-based and landmark-based approximations. Swin TransformerLiu et al. [2021] introduced a hierarchical architecture with shifted window attention to improve scalability and efficiency in vision tasks. Its successor, Swin Transformer V2 Liu et al. [2022b], further enhanced training stability and generalization through log-scaled relative position bias and scaled cosine attention, enabling deployment at a billion-parameter scale. Light Vision Transformer Yang et al. [2022] proposed separate enhanced self-attention mechanisms for low and high-level features to improve efficiency. DynamicViT Rao et al. [2021] proposed learning to prune tokens during inference, enabling adaptive computation without retraining. CrossViT Chen et al. [2021] demonstrated the value of multi-scale token fusion using cross-attention, whereas other works like TokenLearner Ryoo et al. [2021] and AdaViT Meng et al. [2022] introduced dynamic token selection and routing to focus computation on informative regions, similar in spirit to the dynamic attention strategy we explore. ShiftAddViT You et al. [",
    "source": "http://arxiv.org/abs/2506.18791v1",
    "authors": [
      "Suyash Gaurav",
      "Muhammad Farhan Humayun",
      "Jukka Heikkonen",
      "Jatin Chaudhary"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "type": "content"
  },
  {
    "id": "2506.18773v1_abstract",
    "title": "DPG loss functions for learning parameter-to-solution maps by neural networks",
    "content": "Title: DPG loss functions for learning parameter-to-solution maps by neural networks\n\nAbstract: We develop, analyze, and experimentally explore residual-based loss functions\nfor machine learning of parameter-to-solution maps in the context of\nparameter-dependent families of partial differential equations (PDEs). Our\nprimary concern is on rigorous accuracy certification to enhance prediction\ncapability of resulting deep neural network reduced models. This is achieved by\nthe use of variationally correct loss functions. Through one specific example\nof an elliptic PDE, details for establishing the variational correctness of a\nloss function from an ultraweak Discontinuous Petrov Galerkin (DPG)\ndiscretization are worked out. Despite the focus on the example, the proposed\nconcepts apply to a much wider scope of problems, namely problems for which\nstable DPG formulations are available. The issue of {high-contrast} diffusion\nfields and ensuing difficulties with degrading ellipticity are discussed. Both\nnumerical results and theoretical arguments illustrate that for high-contrast\ndiffusion parameters the proposed DPG loss functions deliver much more robust\nperformance than simpler least-squares losses.",
    "source": "http://arxiv.org/abs/2506.18773v1",
    "authors": [
      "Pablo Cortés Castillo",
      "Wolfgang Dahmen",
      "Jay Gopalakrishnan"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "type": "abstract"
  },
  {
    "id": "2506.18773v1_content",
    "title": "DPG loss functions for learning parameter-to-solution maps by neural networks",
    "content": "arXiv:2506.18773v1 [math.NA] 23 Jun 2025DPG LOSS FUNCTIONS FOR LEARNING PARAMETER-TO-SOLUTION MAPS BY NEURAL NETWORKS PABLO CORT ´ES CASTILLO, WOLFGANG DAHMEN, AND JAY GOPALAKRISHNAN Abstract. We develop, analyze, and experimentally explore residual-based loss functions for machine learning of parameter-to-solution maps in the context of parameter-dependent families of partial differential equations (PDEs). Our primary concern is on rigorous accu- racy certification to enhance prediction capability of resulting deep neural network reduced models. This is achieved by the use of variationally correct loss functions. Through one spe- cific example of an elliptic PDE, details for establishing the variational correctness of a loss function from an ultraweak Discontinuous Petrov Galerkin (DPG) discretization are worked out. Despite the focus on the example, the proposed concepts apply to a much wider scope of problems, namely problems for which stable DPG formulations are available. The issue of high-contrast diffusion fields and ensuing difficulties with degrading ellipticity are discussed. Both numerical results and theoretical arguments illustrate that for high-contrast diffusion parameters the proposed DPG loss functions deliver much more robust performance than simpler least-squares losses. 1.Introduction The need to recover information on a physical state of interest from a limited amount of observational data is ubiquitous in scientific and technological applications. To make such tasks feasible, it is crucial to leverage the physical laws that the states obey. However, these are often only partially known. A common way to deal with such uncertainties is to formulate the mathematical model as a system of partial differential equations (PDEs) depending on unknown model data, (such as coefficient fields, initial or boundary conditions, source terms, or constitutive laws), collected into parameters αfrom finite- or infinite-dimensional spaces. We have in mind PDE solutions u(x, α) depending on a spatial variable xin a low-dimensional domain Ω⊂Rdand a parameter variable αin a possibly high-dimensional domain Q. For each parameter instance α∈ Q, the solution u(x, α), also written as u(α) or simply u, is the unique solution of R(u, α) = 0 , (1) for some (generally nonlinear) PDE Rwritten in residual form. The structure and range of Q determine the “design space” or “solution manifold” Mcomprised of the states u(α) that are obtained as solutions of (1) when αtraverses Q. Equation (1) implicitly defines a parameter- to-solution mapF:Q → M . Generally vector spaces in which uis to be found may change from point to point on the manifold. At each parameter instance α∈ Q, the problem (1) for uat the corresponding point on the manifold is referred to as a “fiber problem.” Exploration ofMor solving inverse tasks like state-estimation or parameter-estimation when using Mas a prior, require a large—sometimes prohibitive—number of high-fidelity forward simulations. This calls for generating reduced models providing efficiently computable surrogates for the parameter-to-solution map F. The underlying rationale is that evaluating such a surrogate at any given parameter instance is much more efficient than computing a corresponding high-fidelity approximate solution, see e.g. [7, 18, 27]. Generating a surrogate typically takes 1 DPG LOSS FUNCTIONS FOR NEURAL NETWORKS 2 a substantial computational effort, which though has to be performed only once, and is considered an “offline-cost”. It amortizes quickly when many parameter queries are needed. Generating such surrogates is a central instance of Operator Learning which has lately been attracting considerable attention, see e.g. [8, 29, 30, 31]. In full generality, it aims at approximating mappings between Banach space, hence permitting infinite-dimensional in- puts and outputs. In this latter regard, we are more modest in this paper and focus on a scenario where Qis a finite-dimensional diffusion field in a second-order elliptic boundary value problem. However, we address different challenges which are, in our opinion, of para- mount importance when striving for prediction capability , namely challenges in controlling prediction error in model-compliant norms even in singularly perturbed regimes of parame- ters. The second-order elliptic boundary value problem has numerous applications, a typical one being where urepresents the pressure in a porous medium flow and Rrepresents the simplest version of Darcy’s model. In the construction of surrogates, we use finite elements to discretize the low-dimensional Ωbut use deep neural networks (NN) to discretize Ffrom the high-dimensional Q. This means that our solution predictions take the form uθ(x, α) =X kvk,θ(α)ψk(x) (2) where ψk(x) are standard finite element basis functions and the coefficients vk,θ(α) in the basis expansion are provided by the NN whose settings are determined by a collection θ. While many works discretize spatial dependence also using NN (exceptions include [3, 24, 26]) we opt for (2) to leverage existing finite element techniques and avoid issues in imposing essential boundary conditions on unstructured spatial domains. To put our focus on prediction into perspective, most operator learning approaches are purely data-driven: one first computes a sufficiently large number of high-fidelity solutions that are then used as training samples for performing regression over suitable hypothesis classes for operators—see, e.g., [8, 24, 26, 30, 29, 31]. The accuracy can then be assessed via estimating the “generalization error” incurred. To mitigate the potentially high cost of computing the high-fidelity solutions, other approaches use residual-based loss functions and avoid solving large systems during training. The best known version is PINN (Physics- Informed Neural Network) [22, 28, 34] which employs a Monte-Carlo loss θ∗∈argmin θ∈Θ1 #bQ#bΩX α∈bQ,x∈bΩ R(uθ(x, α), α) 2, (3) to learn an approximation uθ∗from a hypothesis class determined by a finite budget Θ of trainable weights θ. Here bΩis a finite set of spatial samples (such as quadrature points inΩas well as on ∂Ω) and bQ ⊂ Q is a finite collection of model parameters. It is not possible to summarize the burgeoning PINN literature here, but we note that error control and error analysis have received the attention of others: see [1, 10, 36, 38, 40] and references therein. Most of such literature is however concerned with parameter-independent problems and aim to solve just a single fixed PDE, while our focus is on the parameter-to-solution map. While (3) offers great computational convenience (as it only requires evaluation of residuals Rat spatial and parametric samples), it has the following serious drawbacks. Depending on the type of PDE, the residual Rneed not be a function in L2(Ω) (a problem noted in several works [3, 38, 40]). Moreover, when pursuing an ansatz such as (3), the only possible accuracy DPG LOSS FUNCTIONS FOR NEURAL NETWORKS 3 assessment would be based on the loss itself, and a loss of the form (3) need neither be an efficient nor a reliable indicator of the generalization errors. In this paper, we also opt for employing residual-based loss functions but insist on these losses being variationally correct . A precise definition for our situation is provided in Defi- nition 2.4, but to convey the idea right away, when a loss function is variationally correct, its size, at any stage of the optimization process, provides, up to uniform constant factors, a lower and upper bound for the approximation error with respect to the respective model compliant norm (see [3]). As explained later in detail, this is intimately related to a sta- ble variational formulation of the PDE (see also [39]). Again, related ideas in prior works have been confined to solving a single PDE in low spatial dimensions because corresponding residual loss functions are only then practically feasible [5, 6, 15, 23, 32]. Even though the presented concepts apply to a much wider scope of PDE models, namely whenever we have a stable Discontinuous Petrov Galerkin (DPG) formulation [20, 21] at our disposal, in favor of quantitative accuracy studies, we focus here on the homogeneous Dirichlet problem for second-order elliptic equations with parameter-dependent diffusion coefficients. Even when the range Qof parameters guarantees uniform ellipticity, PINN in the form (3) need not be variationally correct. As explained in Section 2 (see also [3]), one key step to realizing variational correctness is to reformulate the PDE first as a well-posed first- order system for the flux and the solution, i.e., for d+ 1 scalar solution components. For strictly positive and bounded diffusion coefficients, there exist actually several distinct stable variational formulations for the first-order system, differing by the choice of trial and test space. In this paper, we discuss two such formulations that mark, in some sense, extreme cases. In the first one, a closed subspace Xof a graph space, determined by homogeneous boundary conditions, serves as the trial space. It can then be shown that the induced operator maps the trial space onto a test space Ywhich equals the ( d+ 1)-fold Cartesian product of L2(Ω), thus giving a well-posed variational formulation in X × Y . This is the First-Order System Least Squares (FOSLS) formulation introduced in [12]. Its residual is well-defined inL2and the L2-residual is uniformly proportional to the corresponding error measured in the graph norm. Incidentally, although PINN is not variationally correct for the original second-order formulation, it is for the FOSLS formulation. How sharp the L2-loss is as a lower and upper bound for the graph norm errors, depends, however, on the size-range of the diffusion coefficients. This raises the main issue addressed in this paper, namely, permitting arbitrarily large size variations in the diffusion coefficient. This is sometimes re",
    "source": "http://arxiv.org/abs/2506.18773v1",
    "authors": [
      "Pablo Cortés Castillo",
      "Wolfgang Dahmen",
      "Jay Gopalakrishnan"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "type": "content"
  }
]